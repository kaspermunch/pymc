{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f5d359-90a0-4310-b1b4-a7167f398f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "#import bambi as bmb\n",
    "import xarray as xr\n",
    "import random\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, FunctionTransformer\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set_context('paper')\n",
    "sns.set_style('ticks')\n",
    "plt.rc(\"axes.spines\", top=False, right=False)\n",
    "with matplotlib.style.context('arviz-doc'):\n",
    "    az_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "sns.set_palette(az_colors)\n",
    "\n",
    "def origo(ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x, y = ax.get_xlim(), ax.get_ylim()\n",
    "    minx, maxx = min(x), max(x)\n",
    "    miny, maxy = min(y), max(y)\n",
    "    plt.ylim(min(0, miny), max(0, maxy))\n",
    "    plt.xlim(min(0, minx), max(0, maxx))\n",
    "\n",
    "class columns:\n",
    "    def __rlshift__(self, df):\n",
    "        \"Left align columns of data frame: df << left()\"\n",
    "        left_aligned_df = df.style.set_properties(**{'text-align': 'left'})\n",
    "        left_aligned_df = left_aligned_df.set_table_styles(\n",
    "        [dict(selector = 'th', props=[('text-align', 'left')])])\n",
    "        display(left_aligned_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8254b3aa-b64c-4afc-91b3-552eaaac4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale = 0.35\n",
    "# d = dict([(k, v*scale) for (k, v) in sns.plotting_context().items() if v is not None])\n",
    "# d['figure.figsize'] = [1.8, 1.3]\n",
    "# matplotlib.rcParams.update(d)\n",
    "# make context for with statement:\n",
    "# #matplotlib.style.context(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861f2eea-3266-401e-89b9-f23f7c5abbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.random.random(10), np.random.random(10)-10)\n",
    "# origo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b21696a-8fc0-4629-978a-ad17645a9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disable annoying \"UserWarning: The figure layout has changed to tight\" message\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning\n",
    "                        # , module='seaborn'\n",
    "                       )\n",
    "warnings.filterwarnings('ignore', category=FutureWarning,\n",
    "                        # module='matplotlib'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b083b-c4cb-42c5-90c4-6710194da1c2",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca23de-9ee2-4eb6-b15b-692fe77d9889",
   "metadata": {},
   "source": [
    "Turn HDF5 Series back into arviz `ELPDData`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8091b4ec-dd10-4721-8260-ebdba1a84e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computed from 800 posterior samples and 2940166 observations log-likelihood matrix.\n",
       "\n",
       "         Estimate       SE\n",
       "elpd_loo -4122802.30  5102.07\n",
       "p_loo      286.87        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "------\n",
       "\n",
       "Pareto k diagnostic values:\n",
       "                           Count   Pct.\n",
       "(-Inf, 0.5]   (good)     2938948  100.0%\n",
       " (0.5, 0.7]   (ok)          1202    0.0%\n",
       "   (0.7, 1]   (bad)           16    0.0%\n",
       "   (1, Inf)   (very bad)       0    0.0%"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arviz.stats import ELPDData\n",
    "loo_hierarchical = ELPDData(pd.read_hdf('loo_hierarchical.h5'))\n",
    "loo_parallel = ELPDData(pd.read_hdf('loo_parallel.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fb8dd2-bb8f-4255-870b-4ee787d5c52a",
   "metadata": {},
   "source": [
    "ArviZ includes two convenience functions to help compare LOO for different models. The first of these functions is compare, which computes LOO (or WAIC) from a set of traces and models and returns a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b99e35-75f8-4a82-ba5a-83cd8526895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these should ofcaues be different models...\n",
    "loo_compare = az.compare({\"hierarchical\": loo_hierarchical, \n",
    "                           \"parallel\": loo_parallel})\n",
    "loo_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a5dc3-600b-48c1-8cb7-6bced64fba14",
   "metadata": {},
   "source": [
    "We have many columns, so let’s check out their meaning one by one:\n",
    "\n",
    "1. The index is the names of the models taken from the keys of the dictionary passed to compare(.).\n",
    "2. rank, the ranking of the models starting from 0 (best model) to the number of models.\n",
    "3. loo, the values of LOO (or WAIC). The DataFrame is always sorted from best LOO/WAIC to worst.\n",
    "4. p_loo, the value of the penalization term. We can roughly think of this value as the estimated effective number of parameters (but do not take that too seriously).\n",
    "5. d_loo, the relative difference between the value of LOO/WAIC for the top-ranked model and the value of LOO/WAIC for each model. For this reason we will always get a value of 0 for the first model.\n",
    "6. weight, the weights assigned to each model. These weights can be loosely interpreted as the probability of each model being true (among the compared models) given the data.\n",
    "se, the standard error for the LOO/WAIC computations. The standard error can be useful to assess the uncertainty of the LOO/WAIC estimates. By default these errors are computed using stacking.\n",
    "7. dse, the standard errors of the difference between two values of LOO/WAIC. The same way that we can compute the standard error for each value of LOO/WAIC, we can compute the standard error of the differences between two values of LOO/WAIC. Notice that both quantities are not necessarily the same, the reason is that the uncertainty about LOO/WAIC is correlated between models. This quantity is always 0 for the top-ranked model.\n",
    "8. warning, If True the computation of LOO/WAIC may not be reliable.\n",
    "9. loo_scale, the scale of the reported values. The default is the log scale as previously mentioned. Other options are deviance – this is the log-score multiplied by -2 (this reverts the order: a lower LOO/WAIC will be better) – and negative-log – this is the log-score multiplied by -1 (as with the deviance scale, a lower value is better)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b0269-8d05-4184-b513-3409a6afa367",
   "metadata": {},
   "source": [
    "The second convenience function takes the output of compare and produces a summary plot in the style of the one used in the book Statistical Rethinking by Richard McElreath (check also this port of the examples in the book to PyMC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d59214-ab91-4a51-8408-1cb2aa8a23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(loo_compare, insample_dev=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c963c-69aa-4e4a-b485-cac799f785c0",
   "metadata": {},
   "source": [
    "The empty circle represents the values of LOO and the black error bars associated with them are the values of the standard deviation of LOO.\n",
    "\n",
    "The value of the highest LOO, i.e the best estimated model, is also indicated with a vertical dashed grey line to ease comparison with other LOO values.\n",
    "\n",
    "For all models except the top-ranked one we also get a triangle indicating the value of the difference of WAIC between that model and the top model and a grey error bar indicating the standard error of the differences between the top-ranked WAIC and WAIC for each model.\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "Though we might expect the hierarchical model to outperform a complete pooling model, there is little to choose between the models in this case, given that both models gives very similar values of the information criteria. This is more clearly appreciated when we take into account the uncertainty (in terms of standard errors) of LOO and WAIC.\n",
    "\n",
    "[https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/model_comparison.html](https://www.pymc.io/projects/docs/en/stable/learn/core_notebooks/model_comparison.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f7f74-edc3-4200-a4dd-652be20defb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_elpd(\n",
    "    {\"hierarchical\": elpd_hierarchical, \n",
    "     \"parallel\": elpd_parallel},\n",
    "    xlabels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca6f9e6-556e-4dfa-97b0-e3a5d6cd7511",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1546dc11-8db2-48e9-a294-0d48c0373290",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata_hierarchical.posterior.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f356d3-0093-435f-900b-cdd7e0408628",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.extract(idata_hierarchical, num_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e890980-145f-4b52-84fc-480efc907020",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['full_species', 'NE_MEAN']].drop_duplicates().set_index('full_species').loc[t.Species, 'NE_MEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c52077-0ad9-4b7f-b02d-8a814fef2f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = idata.posterior.mean(dim=['chain', 'draw'])\n",
    "sns.barplot(data=pd.DataFrame(dict(x=d.Species, y=d.b)), x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bec66a-74eb-4ed4-a494-fdd7070bf202",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066ac40-7de0-4ec2-85b1-4bf4114f9ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722dde4-7f8c-4ebf-aba0-c002e6c3a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "az.plot_bf(idata.posterior, var_name=\"h1\") ;\n",
    "#sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53d446-f91c-4a7a-b978-732ac6f53155",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(idata.posterior, var_names=['h0', 'h1']) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969cf950-f9a0-41dc-a7f2-7f07d298640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(idata, var_names=['a', 'b'], figsize=(16, 15))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a89285-8060-4f2a-8dcd-90b0cb3abadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(idata, var_names=['a', 'b'], combine_dims={'Species'}, figsize=(6, 5)) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5905e92-0445-4325-89b6-dcc0c05488e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(idata.posterior, var_names=['g0', 'g1', 'h0', 'h1'], ess=True, figsize=(6, 5)) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1098b90-cb60-4e24-9f23-e8e503a62a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(idata.posterior, var_names=['b'], ess=True, figsize=(15, 100)) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb39cb-307f-4262-aad6-1fb5350ec9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import timeit\n",
    "import dask\n",
    "\n",
    "from arviz.utils import conditional_jit, Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a6ac7-cc3f-4e8a-8c9c-e79d87ac01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional imports\n",
    "from dask.distributed import Client\n",
    "from dask.diagnostics import ResourceProfiler\n",
    "\n",
    "from bokeh.resources import INLINE\n",
    "import bokeh.io\n",
    "\n",
    "bokeh.io.output_notebook(INLINE)\n",
    "\n",
    "%reload_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bba6d-bc91-4491-a06d-1db43d8996b6",
   "metadata": {},
   "source": [
    "> ResourceProfiler() and Client are optional. They are only used for the visualizing and profiling the dask enabled methods. ArviZ-Dask integration can be used without using these objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c4aac2-e945-4987-98fa-934982cd6462",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(threads_per_worker=4, n_workers=1, memory_limit=\"1.2GB\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ceeca1-f20d-4e04-91ac-ea8f85941192",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_size = 250_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a567aa6-8dd2-4b4a-809a-3e97bc2bcabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit \n",
    "data = np.random.randn(array_size)\n",
    "np.var(data, ddof=1)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c61535-ebd7-4baf-962d-3c4300812b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit data = dask.array.random.normal(size=array_size, chunks=\"auto\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861398b4-1463-4ace-9a52-8123db4a9174",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = dask.array.var(data, ddof=1)\n",
    "var.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d8752-1b3a-4f24-abdb-4d4d006b9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ResourceProfiler(dt=0.25) as rprof:\n",
    "    var.compute()\n",
    "\n",
    "rprof.visualize();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
